server:
  host: "0.0.0.0"
  port: 50051
  access_token: ""
chat:
  proxy_key: ""
  proxy_base_url: "http://ip:4002/v1"
  # 使用的训练模型
  model: "gpt-3.5-turbo"
  # 单次请求的上下文总长度，包括 请求消息+completion.maxToken 两者总计不能超过4097
  max_tokens: 4096
  # 表示语言模型输出的随机性和创造性
  # 取值范围0~1，值越大随机性和创造性越高
  temperature: 0.8
  # 用于生成文本时控制选词的随机程度
  # 即下一个预测单词考虑的概率范围
  # 取值范围0~1，例如：0.5，表示考虑选择的单词累计概率大于等于0.5
  top_p: 0.9
  # 存在惩罚，用于生成文本时控制重复使用单词的程度
  # 取值0~1，0表示不惩罚，1表示完全禁止重复单词
  # 完全进制重复单词会影响生成文本的流畅性和连贯性
  presence_penalty: 0.8
  # 用于控制模型生成回复时重复单词出现的频率
  # 取值0~1，值越大生成的回复会更注重避免使用已经出现的单词
  frequency_penalty: 0.5
  # AI助手特征描述
  bot_desc: "你是一个AI助手，我需要你模拟一名资深软件工程师来回答我的问题"
  # 上下文缓存的时长，单位是s
  context_ttl: 1800
  # 上下文的消息条数
  context_len: 4
  # 单次请求，保留的响应tokens数量
  min_response_tokens: 2048
redis:
  host: ""
  port: 6379
  pwd: ""
depend_on_services:
  tokenizer:
    address: "http://tokenizer:5001"
    access_token: ""
  chatgpt_data:
    address: "chatgpt-datas:50052"
    access_token: ""
  chatgpt_sensitive:
    address: "sensitive:50053"
    access_token: ""
  chatgpt_keywords:
    address: "keywords:50054"
    access_token: ""
log:
  # panic,fatal,error,warn,warning,info,debug,trace
  level: "info"
  log_path: "runtime/app.log"